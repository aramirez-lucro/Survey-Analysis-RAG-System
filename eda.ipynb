{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Total Sample</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>UK County</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 137</th>\n",
       "      <th>Unnamed: 138</th>\n",
       "      <th>Unnamed: 139</th>\n",
       "      <th>Unnamed: 140</th>\n",
       "      <th>Unnamed: 141</th>\n",
       "      <th>Unnamed: 142</th>\n",
       "      <th>Unnamed: 143</th>\n",
       "      <th>Unnamed: 144</th>\n",
       "      <th>Unnamed: 145</th>\n",
       "      <th>Unnamed: 146</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Demographics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>Female</td>\n",
       "      <td></td>\n",
       "      <td>North East</td>\n",
       "      <td>North West</td>\n",
       "      <td>Yorkshire &amp; The Humber</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>...</td>\n",
       "      <td>Lush</td>\n",
       "      <td>Lidl</td>\n",
       "      <td>Ecover</td>\n",
       "      <td>Oceansaver</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>No / Don't Know</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Nike</td>\n",
       "      <td>No Group</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total</td>\n",
       "      <td>1009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>477</td>\n",
       "      <td>532</td>\n",
       "      <td></td>\n",
       "      <td>45</td>\n",
       "      <td>114</td>\n",
       "      <td>87</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>714</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47%</td>\n",
       "      <td>53%</td>\n",
       "      <td></td>\n",
       "      <td>4%</td>\n",
       "      <td>11%</td>\n",
       "      <td>9%</td>\n",
       "      <td>8%</td>\n",
       "      <td>...</td>\n",
       "      <td>2%</td>\n",
       "      <td>4%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>64%</td>\n",
       "      <td>1%</td>\n",
       "      <td>2%</td>\n",
       "      <td>10%</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>Nike</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027254</td>\n",
       "      <td>0.018797</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>No Group</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119497</td>\n",
       "      <td>0.103383</td>\n",
       "      <td></td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>629 rows Ã— 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 Total Sample  Unnamed: 2    Gender Unnamed: 4 Unnamed: 5  \\\n",
       "0    Demographics          NaN         NaN      Male     Female              \n",
       "1             NaN          NaN         NaN       NaN        NaN        NaN   \n",
       "2          Gender          NaN         NaN       NaN        NaN        NaN   \n",
       "3           Total         1009         NaN       477        532              \n",
       "4             NaN         100%         NaN       47%        53%              \n",
       "..            ...          ...         ...       ...        ...        ...   \n",
       "624           NaN           1%         NaN  0.025157          0              \n",
       "625          Nike           23         NaN        13         10              \n",
       "626           NaN           2%         NaN  0.027254   0.018797              \n",
       "627      No Group          112         NaN        57         55              \n",
       "628           NaN          10%         NaN  0.119497   0.103383              \n",
       "\n",
       "      UK County  Unnamed: 7              Unnamed: 8     Unnamed: 9  ...  \\\n",
       "0    North East  North West  Yorkshire & The Humber  East Midlands  ...   \n",
       "1           NaN         NaN                     NaN            NaN  ...   \n",
       "2           NaN         NaN                     NaN            NaN  ...   \n",
       "3            45         114                      87             78  ...   \n",
       "4            4%         11%                      9%             8%  ...   \n",
       "..          ...         ...                     ...            ...  ...   \n",
       "624           0    0.017544                       0       0.025641  ...   \n",
       "625           0           4                       1              0  ...   \n",
       "626           0    0.035088                0.011494              0  ...   \n",
       "627           4          14                      12              5  ...   \n",
       "628    0.088889    0.122807                0.137931       0.064103  ...   \n",
       "\n",
       "    Unnamed: 137 Unnamed: 138 Unnamed: 139 Unnamed: 140 Unnamed: 141  \\\n",
       "0           Lush         Lidl       Ecover   Oceansaver        Tesco   \n",
       "1            NaN          NaN          NaN          NaN          NaN   \n",
       "2            NaN          NaN          NaN          NaN          NaN   \n",
       "3             18           45           21            3           15   \n",
       "4             2%           4%           2%           0%           1%   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "624            0            0            0            0            0   \n",
       "625            0            0            0            0            0   \n",
       "626            0            0            0            0            0   \n",
       "627            0            0            0            0            0   \n",
       "628            0            0            0            0            0   \n",
       "\n",
       "        Unnamed: 142 Unnamed: 143 Unnamed: 144 Unnamed: 145 Unnamed: 146  \n",
       "0    No / Don't Know        Tesla         Nike     No Group               \n",
       "1                NaN          NaN          NaN          NaN          NaN  \n",
       "2                NaN          NaN          NaN          NaN          NaN  \n",
       "3                714           12           23          112               \n",
       "4                64%           1%           2%          10%               \n",
       "..               ...          ...          ...          ...          ...  \n",
       "624                0            0            0            0               \n",
       "625                0            0            0            0               \n",
       "626                0            0            0            0               \n",
       "627                0            0            0            0               \n",
       "628                0            0            0            0               \n",
       "\n",
       "[629 rows x 147 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "sustainability_path = \"backend/data/Dataset 1 (Sustainability Research Results).xlsx\"\n",
    "\n",
    "sustainability_df = pd.read_excel(sustainability_path, engine='openpyxl')\n",
    "\n",
    "sustainability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_blocks(df):\n",
    "    # Identify the rows where questions start\n",
    "    question_rows = df[df.iloc[:, 0].str.contains('Question', na=False)].index\n",
    "\n",
    "    # Create a dictionary to store the split dataframes\n",
    "    dfs = {}\n",
    "\n",
    "    # Iterate over the question rows and split the dataframe\n",
    "    for i, start_row in enumerate(question_rows):\n",
    "        end_row = question_rows[i + 1] if i + 1 < len(question_rows) else len(df)\n",
    "        question_text = df.iloc[start_row, 0]\n",
    "        dfs[question_text] = df.iloc[start_row:end_row].reset_index(drop=True)#.fillna('')\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sustainability_dfs = extract_data_blocks(sustainability_df)\n",
    "\n",
    "len(sustainability_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframes to excel files\n",
    "for i, (key, df) in enumerate(sustainability_dfs.items()):\n",
    "    key = \"_\".join(key.split(\" \")[:2]).lower()\n",
    "    df.to_excel(f\"backend/data/processed/sustainability_{key}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_path = \"backend/data/Dataset 2 (Christmas Research Results).xlsx\"\n",
    "christmas_df = pd.read_excel(christmas_path, engine='openpyxl')\n",
    "\n",
    "christmas_dfs = extract_data_blocks(christmas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (key, df) in enumerate(christmas_dfs.items()):\n",
    "    key = \"_\".join(key.split(\" \")[:2]).lower()\n",
    "    df.to_excel(f\"backend/data/processed/christmas_{key}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the SurveyAnalysisRAGSystem\n",
    "import pandas as pd\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from backend.utils.logging import get_logger\n",
    "from time import time\n",
    "from glob import glob\n",
    "\n",
    "# Initialize logger\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Set your OpenAI API Key\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "class DocumentLoader:\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths\n",
    "\n",
    "    def load_documents(self):\n",
    "        \"\"\"Load and split the documents from the Excel files using the UnstructuredExcelLoader.\"\"\"\n",
    "        logger.info(f\"Loading documents from {len(self.file_paths)} files: {self.file_paths}\")\n",
    "        docs = [self._process(file_path) for file_path in self.file_paths]\n",
    "        documents = sum(docs, [])  # Flatten the list of lists\n",
    "        logger.info(f\"Total documents loaded: {len(documents)}\")\n",
    "        return documents\n",
    "\n",
    "    def _process(self, file_path):\n",
    "        logger.info(f\"Processing file: {file_path}\")\n",
    "        docs = UnstructuredExcelLoader(file_path, mode='elements').load_and_split()\n",
    "        for doc in docs:\n",
    "            dataset_id = file_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "            doc.metadata['dataset_id'] = dataset_id\n",
    "        logger.info(f\"Loaded {len(docs)} documents from {file_path}\")\n",
    "        return docs\n",
    "\n",
    "class VectorStore:\n",
    "    def __init__(self, documents, embedding_model):\n",
    "        self.documents = documents\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "    def create_vectorstore(self):\n",
    "        \"\"\"Generate embeddings for the documents and create a FAISS vectorstore for retrieval.\"\"\"\n",
    "        logger.info(\"Generating embeddings for documents\")\n",
    "        embeddings = OpenAIEmbeddings(model=self.embedding_model)\n",
    "        vectorstore = FAISS.from_documents(self.documents, embeddings)\n",
    "        logger.info(f\"Vectorstore created successfully with {len(self.documents)} documents\")\n",
    "        return vectorstore\n",
    "\n",
    "class PromptTemplateFactory:\n",
    "    @staticmethod\n",
    "    def create_prompt_template():\n",
    "        \"\"\"Define the prompt template for querying the model with relevant context.\"\"\"\n",
    "        logger.info(\"Defining prompt template\")\n",
    "        return ChatPromptTemplate(\n",
    "            input_variables=['context', 'question'],\n",
    "            messages=[\n",
    "                HumanMessagePromptTemplate(\n",
    "                    prompt=PromptTemplate(\n",
    "                        input_variables=['context', 'question'],\n",
    "                        template=(\n",
    "                            \"You are an assistant for question-answering tasks. \"\n",
    "                            \"Specialized in data analysis and interpreting survey data. \"\n",
    "                            \"Use the following pieces of retrieved context to answer the question. \"\n",
    "                            \"If you don't know the answer, just say that you don't know. \"\n",
    "                            \"Use three sentences maximum and keep the answer concise.\\n\"\n",
    "                            \"Question: {question} \\n\"\n",
    "                            \"Context: {context} \\n\"\n",
    "                            \"Answer:\"\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "class SurveyAnalysisRAGSystem:\n",
    "    def __init__(self, file_path, embedding_model=\"text-embedding-3-large\", llm_model=\"gpt-4o-mini\"):\n",
    "        logger.info(\"Initializing SurveyAnalysisRAGSystem\")\n",
    "        self.file_paths = glob(file_path + \"*.xlsx\")\n",
    "        self.embedding_model = embedding_model\n",
    "        self.llm_model = llm_model\n",
    "        \n",
    "        # Load documents\n",
    "        self.documents = DocumentLoader(self.file_paths).load_documents()\n",
    "\n",
    "        # Create vector embeddings and store them in FAISS\n",
    "        self.vectorstore = VectorStore(self.documents, self.embedding_model).create_vectorstore()\n",
    "\n",
    "        # Initialize the language model for generating insights\n",
    "        self.llm = ChatOpenAI(model=self.llm_model, temperature=0.25, max_tokens=1024)\n",
    "\n",
    "        # Setup prompt template for query generation\n",
    "        self.prompt = PromptTemplateFactory.create_prompt_template()\n",
    "\n",
    "    @staticmethod\n",
    "    def format_docs(docs):    \n",
    "        return \"\\n\\n\".join(str(doc.metadata[\"filename\"]) + \"\\n\\n\" + doc.page_content for doc in docs) \n",
    "\n",
    "    def generate_answer(self, query, dataset_id, k=16):\n",
    "        \"\"\"Generate an answer for the given query using the specified dataset.\"\"\"\n",
    "        logger.info(f\"Generating answer for query: {query} with dataset_id: {dataset_id}\")\n",
    "        st = time()\n",
    "        self.retriever = self.vectorstore.as_retriever(\n",
    "            search_type=\"mmr\", # mmr\n",
    "            search_kwargs={'k': k, 'lambda_mult': 0.25, 'filter': {'dataset_id': dataset_id}}\n",
    "        )\n",
    "        self.qa_chain = (\n",
    "            {\n",
    "                \"context\": self.retriever | self.format_docs,\n",
    "                \"question\": RunnablePassthrough(),\n",
    "            }\n",
    "            | self.prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Invoking QA chain...\")\n",
    "        output = {\"result\" : self.qa_chain.invoke(query)}\n",
    "        output[\"time_taken\"] = time() - st\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 20:17:19,752 - __main__ - INFO - Initializing SurveyAnalysisRAGSystem with example file paths\n",
      "2024-10-17 20:17:19,753 - __main__ - INFO - Initializing SurveyAnalysisRAGSystem\n",
      "2024-10-17 20:17:19,755 - __main__ - INFO - Loading documents from 29 files: ['backend/data/processed/sustainability_question_15.xlsx', 'backend/data/processed/sustainability_question_7.xlsx', 'backend/data/processed/sustainability_question_13.xlsx', 'backend/data/processed/christmas_question_1.xlsx', 'backend/data/processed/sustainability_question_9.xlsx', 'backend/data/processed/christmas_question_3.xlsx', 'backend/data/processed/sustainability_question_2.xlsx', 'backend/data/processed/sustainability_question_14.xlsx', 'backend/data/processed/sustainability_question_19.xlsx', 'backend/data/processed/sustainability_question_1.xlsx', 'backend/data/processed/sustainability_question_8.xlsx', 'backend/data/processed/sustainability_question_17.xlsx', 'backend/data/processed/christmas_question_4.xlsx', 'backend/data/processed/sustainability_question_6.xlsx', 'backend/data/processed/sustainability_question_11.xlsx', 'backend/data/processed/sustainability_question_16.xlsx', 'backend/data/processed/sustainability_question_3.xlsx', 'backend/data/processed/sustainability_question_10.xlsx', 'backend/data/processed/christmas_question_5.xlsx', 'backend/data/processed/christmas_question_6.xlsx', 'backend/data/processed/sustainability_question_18.xlsx', 'backend/data/processed/christmas_question_7.xlsx', 'backend/data/processed/sustainability_question_4.xlsx', 'backend/data/processed/christmas_question_2.xlsx', 'backend/data/processed/christmas_questions.xlsx', 'backend/data/processed/sustainability_questions.xlsx', 'backend/data/processed/sustainability_question_5.xlsx', 'backend/data/processed/sustainability_question_12.xlsx', 'backend/data/processed/sustainability_question_20.xlsx']\n",
      "2024-10-17 20:17:19,756 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_15.xlsx\n",
      "2024-10-17 20:17:22,449 - __main__ - INFO - Loaded 3 documents from backend/data/processed/sustainability_question_15.xlsx\n",
      "2024-10-17 20:17:22,450 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_7.xlsx\n",
      "2024-10-17 20:17:23,238 - __main__ - INFO - Loaded 14 documents from backend/data/processed/sustainability_question_7.xlsx\n",
      "2024-10-17 20:17:23,239 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_13.xlsx\n",
      "2024-10-17 20:17:24,074 - __main__ - INFO - Loaded 11 documents from backend/data/processed/sustainability_question_13.xlsx\n",
      "2024-10-17 20:17:24,075 - __main__ - INFO - Processing file: backend/data/processed/christmas_question_1.xlsx\n",
      "2024-10-17 20:17:24,328 - __main__ - INFO - Loaded 4 documents from backend/data/processed/christmas_question_1.xlsx\n",
      "2024-10-17 20:17:24,329 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_9.xlsx\n",
      "2024-10-17 20:17:24,553 - __main__ - INFO - Loaded 3 documents from backend/data/processed/sustainability_question_9.xlsx\n",
      "2024-10-17 20:17:24,554 - __main__ - INFO - Processing file: backend/data/processed/christmas_question_3.xlsx\n",
      "2024-10-17 20:17:24,670 - __main__ - INFO - Loaded 2 documents from backend/data/processed/christmas_question_3.xlsx\n",
      "2024-10-17 20:17:24,672 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_2.xlsx\n",
      "2024-10-17 20:17:25,141 - __main__ - INFO - Loaded 4 documents from backend/data/processed/sustainability_question_2.xlsx\n",
      "2024-10-17 20:17:25,141 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_14.xlsx\n",
      "2024-10-17 20:17:25,332 - __main__ - INFO - Loaded 3 documents from backend/data/processed/sustainability_question_14.xlsx\n",
      "2024-10-17 20:17:25,333 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_19.xlsx\n",
      "2024-10-17 20:17:25,529 - __main__ - INFO - Loaded 4 documents from backend/data/processed/sustainability_question_19.xlsx\n",
      "2024-10-17 20:17:25,530 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_1.xlsx\n",
      "2024-10-17 20:17:25,804 - __main__ - INFO - Loaded 4 documents from backend/data/processed/sustainability_question_1.xlsx\n",
      "2024-10-17 20:17:25,805 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_8.xlsx\n",
      "2024-10-17 20:17:26,028 - __main__ - INFO - Loaded 4 documents from backend/data/processed/sustainability_question_8.xlsx\n",
      "2024-10-17 20:17:26,029 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_17.xlsx\n",
      "2024-10-17 20:17:26,687 - __main__ - INFO - Loaded 6 documents from backend/data/processed/sustainability_question_17.xlsx\n",
      "2024-10-17 20:17:26,688 - __main__ - INFO - Processing file: backend/data/processed/christmas_question_4.xlsx\n",
      "2024-10-17 20:17:27,320 - __main__ - INFO - Loaded 12 documents from backend/data/processed/christmas_question_4.xlsx\n",
      "2024-10-17 20:17:27,321 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_6.xlsx\n",
      "2024-10-17 20:17:28,390 - __main__ - INFO - Loaded 14 documents from backend/data/processed/sustainability_question_6.xlsx\n",
      "2024-10-17 20:17:28,392 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_11.xlsx\n",
      "2024-10-17 20:17:28,950 - __main__ - INFO - Loaded 5 documents from backend/data/processed/sustainability_question_11.xlsx\n",
      "2024-10-17 20:17:28,951 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_16.xlsx\n",
      "2024-10-17 20:17:29,163 - __main__ - INFO - Loaded 3 documents from backend/data/processed/sustainability_question_16.xlsx\n",
      "2024-10-17 20:17:29,164 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_3.xlsx\n",
      "2024-10-17 20:17:29,364 - __main__ - INFO - Loaded 3 documents from backend/data/processed/sustainability_question_3.xlsx\n",
      "2024-10-17 20:17:29,365 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_10.xlsx\n",
      "2024-10-17 20:17:29,667 - __main__ - INFO - Loaded 6 documents from backend/data/processed/sustainability_question_10.xlsx\n",
      "2024-10-17 20:17:29,668 - __main__ - INFO - Processing file: backend/data/processed/christmas_question_5.xlsx\n",
      "2024-10-17 20:17:30,175 - __main__ - INFO - Loaded 4 documents from backend/data/processed/christmas_question_5.xlsx\n",
      "2024-10-17 20:17:30,176 - __main__ - INFO - Processing file: backend/data/processed/christmas_question_6.xlsx\n",
      "2024-10-17 20:17:30,357 - __main__ - INFO - Loaded 3 documents from backend/data/processed/christmas_question_6.xlsx\n",
      "2024-10-17 20:17:30,358 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_18.xlsx\n",
      "2024-10-17 20:17:31,025 - __main__ - INFO - Loaded 13 documents from backend/data/processed/sustainability_question_18.xlsx\n",
      "2024-10-17 20:17:31,026 - __main__ - INFO - Processing file: backend/data/processed/christmas_question_7.xlsx\n",
      "2024-10-17 20:17:31,562 - __main__ - INFO - Loaded 5 documents from backend/data/processed/christmas_question_7.xlsx\n",
      "2024-10-17 20:17:31,563 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_4.xlsx\n",
      "2024-10-17 20:17:31,750 - __main__ - INFO - Loaded 3 documents from backend/data/processed/sustainability_question_4.xlsx\n",
      "2024-10-17 20:17:31,751 - __main__ - INFO - Processing file: backend/data/processed/christmas_question_2.xlsx\n",
      "2024-10-17 20:17:31,864 - __main__ - INFO - Loaded 2 documents from backend/data/processed/christmas_question_2.xlsx\n",
      "2024-10-17 20:17:31,865 - __main__ - INFO - Processing file: backend/data/processed/christmas_questions.xlsx\n",
      "2024-10-17 20:17:31,907 - __main__ - INFO - Loaded 2 documents from backend/data/processed/christmas_questions.xlsx\n",
      "2024-10-17 20:17:31,908 - __main__ - INFO - Processing file: backend/data/processed/sustainability_questions.xlsx\n",
      "2024-10-17 20:17:31,970 - __main__ - INFO - Loaded 2 documents from backend/data/processed/sustainability_questions.xlsx\n",
      "2024-10-17 20:17:31,971 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_5.xlsx\n",
      "2024-10-17 20:17:32,318 - __main__ - INFO - Loaded 6 documents from backend/data/processed/sustainability_question_5.xlsx\n",
      "2024-10-17 20:17:32,319 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_12.xlsx\n",
      "2024-10-17 20:17:32,513 - __main__ - INFO - Loaded 3 documents from backend/data/processed/sustainability_question_12.xlsx\n",
      "2024-10-17 20:17:32,514 - __main__ - INFO - Processing file: backend/data/processed/sustainability_question_20.xlsx\n",
      "2024-10-17 20:17:33,131 - __main__ - INFO - Loaded 6 documents from backend/data/processed/sustainability_question_20.xlsx\n",
      "2024-10-17 20:17:33,132 - __main__ - INFO - Total documents loaded: 154\n",
      "2024-10-17 20:17:33,133 - __main__ - INFO - Generating embeddings for documents\n",
      "2024-10-17 20:17:40,277 - __main__ - INFO - Vectorstore created successfully with 154 documents\n",
      "2024-10-17 20:17:40,299 - __main__ - INFO - Defining prompt template\n"
     ]
    }
   ],
   "source": [
    "# Define your file paths\n",
    "file_path = 'backend/data/processed/'\n",
    "\n",
    "# Initialize the system with the file paths\n",
    "logger.info(\"Initializing SurveyAnalysisRAGSystem with example file paths\")\n",
    "survey_system = SurveyAnalysisRAGSystem(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 20:17:40,312 - __main__ - INFO - Querying system with: summarize results for question 1\n",
      "2024-10-17 20:17:40,314 - __main__ - INFO - Generating answer for query: summarize results for question 1 with dataset_id: sustainability\n",
      "2024-10-17 20:17:40,316 - __main__ - INFO - Invoking QA chain...\n",
      "2024-10-17 20:17:43,834 - __main__ - INFO - Response: {'result': 'The results for Question 1 indicate that respondents ranked various issues facing the UK, with a total sample of 1009 participants. The specific rankings of the issues were not provided in the context, so I cannot summarize the exact results. If you have access to the detailed rankings or data, I could help interpret that information further.', 'time_taken': 3.5185585021972656}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for Question 1 indicate that respondents ranked various issues facing the UK, with a total sample of 1009 participants. The specific rankings of the issues were not provided in the context, so I cannot summarize the exact results. If you have access to the detailed rankings or data, I could help interpret that information further.\n"
     ]
    }
   ],
   "source": [
    "# Query the system with a specific question\n",
    "query = \"summarize results for question 1\"\n",
    "logger.info(f\"Querying system with: {query}\")\n",
    "\n",
    "response = survey_system.generate_answer(query, dataset_id='sustainability', k=16)\n",
    "\n",
    "# Print the response\n",
    "logger.info(f\"Response: {response}\")\n",
    "\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
